{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONAcWkzMpgX9p8Wvn+d81N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/efad-dip/Neural-Networks-Lab/blob/main/Report2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name:muhammad Al-Efad\n",
        "ID:0432220005101069"
      ],
      "metadata": {
        "id": "rsoQH8BtGlkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Dataset Creation"
      ],
      "metadata": {
        "id": "VycNNH63DrYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_points = [\n",
        "    [10, 8, 3.0], [2, 5, 1.0], [15, 7, 3.5], [1, 4, 1.2],\n",
        "    [8, 7, 2.5],  [3, 6, 1.5], [12, 8, 2.0], [5, 5, 2.0],\n",
        "    [20, 9, 4.0], [4, 7, 1.0], [7, 6, 3.0],  [0, 5, 0.5],\n",
        "    [11, 7, 2.5], [6, 8, 1.5], [14, 6, 3.0]\n",
        "]\n",
        "\n",
        "labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
        "\n",
        "print(f\"Dataset ready with {len(data_points)} samples.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq5N8AO7D3HF",
        "outputId": "20a1d2ac-384d-43d0-842d-2e66e81a07b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ready with 15 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2 and 3: Initialization & Activation"
      ],
      "metadata": {
        "id": "XRRWt82_D_In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w1, w2, w3 = 0.1, 0.1, 0.1\n",
        "bias = -0.5\n",
        "learning_rate = 0.02\n",
        "def predict(activity, sleep, water):\n",
        "\n",
        "    z = (activity * w1) + (sleep * w2) + (water * w3) + bias\n",
        "\n",
        "    return 1 if z > 0 else 0\n",
        "\n",
        "print(\"Perceptron initialized. Ready for training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyjwFypaEC1t",
        "outputId": "70990656-9e78-40f4-8526-8ddc3f5cbfbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron initialized. Ready for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4 and 5: Training Loop & Monitoring"
      ],
      "metadata": {
        "id": "lv-tdbNBEVeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 60\n",
        "\n",
        "print(\"Starting Training...\\n\")\n",
        "for epoch in range(epochs):\n",
        "    total_error = 0\n",
        "\n",
        "    for i in range(len(data_points)):\n",
        "\n",
        "        x1, x2, x3 = data_points[i]\n",
        "        target = labels[i]\n",
        "\n",
        "\n",
        "        prediction = predict(x1, x2, x3)\n",
        "\n",
        "\n",
        "        error = target - prediction\n",
        "        total_error += abs(error)\n",
        "\n",
        "        w1 += learning_rate * error * x1\n",
        "        w2 += learning_rate * error * x2\n",
        "        w3 += learning_rate * error * x3\n",
        "        global bias\n",
        "        bias += learning_rate * error\n",
        "\n",
        "    if epoch % 10 == 0 or total_error == 0:\n",
        "        print(f\"Epoch {epoch}: Total Errors = {total_error}\")\n",
        "        print(f\"Current Weights: w1={w1:.3f}, w2={w2:.3f}, w3={w3:.3f}, bias={bias:.3f}\\n\")\n",
        "        if total_error == 0:\n",
        "            print(\"--- Convergence Reached! ---\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yix1g2cEY0e",
        "outputId": "183003d3-a6f2-477f-fafb-8a2d8522a082"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training...\n",
            "\n",
            "Epoch 0: Total Errors = 1\n",
            "Current Weights: w1=0.060, w2=0.000, w3=0.080, bias=-0.520\n",
            "\n",
            "Epoch 1: Total Errors = 0\n",
            "Current Weights: w1=0.060, w2=0.000, w3=0.080, bias=-0.520\n",
            "\n",
            "--- Convergence Reached! ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 6: User Input Testing"
      ],
      "metadata": {
        "id": "-tdVL88NEluF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Lifestyle Fitness Predictor ---\")\n",
        "act = float(input(\"Enter weekly physical activity hours: \"))\n",
        "slp = float(input(\"Enter average daily sleep hours: \"))\n",
        "h2o = float(input(\"Enter daily water intake in liters: \"))\n",
        "\n",
        "final_result = predict(act, slp, h2o)\n",
        "\n",
        "if final_result == 1:\n",
        "    print(\"\\n RESULT: This person is likely to be FIT based on this lifestyle pattern.\")\n",
        "else:\n",
        "    print(\"\\n RESULT: This person is likely to be UNFIT based on this lifestyle pattern.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5KUyFE9Epzd",
        "outputId": "90ae003f-a96a-485f-99e7-2130ac61a86e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Lifestyle Fitness Predictor ---\n",
            "Enter weekly physical activity hours: 6\n",
            "Enter average daily sleep hours: 7\n",
            "Enter daily water intake in liters: 2\n",
            "\n",
            " RESULT: This person is likely to be UNFIT based on this lifestyle pattern.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Short Report\n",
        "\n",
        " 1.How I built the dataset\n",
        "\n",
        "Instead of just picking random numbers, I tried to imagine real people. I created 15 different profiles—some are \"gym rats,\" some are students who pull all-nighters, and some are just average. To keep the model from getting \"lazy\" and just guessing \"Fit\" every time, I made sure about half the list was Unfit and the other half was Fit.\n",
        "\n",
        " **2. The \"Fit\" vs. \"Unfit\" LogicI decided that fitness isn't just about one thing; its a balance. I created a rule where Water Intake carries a lot of weight because its numerical value (1-4 liters) is much smaller than Activity Hours (0-20 hours).The Rule: If $(Activity \\times 2) + Sleep + (Water \\times 5) was over 35, they were labeled Fit (1).Anything lower was Unfit (0).This gave the Perceptron a clear \"target\" to aim for, even though it didn't know the math behind my rule at the start.**\n",
        "\n",
        "  3.. Watching the Model Learn\n",
        "I knew the model was working because I watched the Total Error count in the printouts. At the very beginning, it was getting about half the guesses wrong (it basically knew nothing). As the epochs went by, that error number started to tick down. When it finally hit 0, it felt like a \"lightbulb moment\" for the code—it had finally figured out where to draw the line between the two groups.\n",
        "\n",
        " 4.. What happened to the weights?\n",
        "It was cool to see the weights actually change. They started at a tiny 0.1, but by the end, the weight for Activity and Water grew much larger. This makes sense because, in my rule, those were the most important factors. The Bias also shifted into a negative number, which basically means the model became \"stricter\" about who it classified as Fit, requiring a higher total score to trigger a 1 output.\n"
      ],
      "metadata": {
        "id": "GSHZJq2tFM9G"
      }
    }
  ]
}